{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai\n",
    "import os\n",
    "import ollama\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OpenAI's Answer:\n",
      "The code you provided is a Python expression that uses a generator and set comprehension. Let's break down what it does step by step:\n",
      "\n",
      "1. **Set Comprehension**: \n",
      "   ```python\n",
      "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "   ```\n",
      "   This part creates a set of unique authors from a collection of `books`. The set comprehension iterates through each `book` in the `books` iterable and applies the following:\n",
      "   - `book.get(\"author\")` retrieves the value associated with the `\"author\"` key from each `book` dictionary. If the key doesn't exist, `get` will return `None`.\n",
      "   - The `if book.get(\"author\")` condition ensures that only books where the author is not `None` (or an empty string) are included.\n",
      "   - As a result, this produces a set of unique authors from the `books` collection.\n",
      "\n",
      "2. **Yield Statement**: \n",
      "   ```python\n",
      "   yield from ...\n",
      "   ```\n",
      "   The `yield from` expression is used in Python to delegate part of a generator's operations to another generator or iterable. In this case, it yields each item from the set created by the set comprehension one at a time.\n",
      "\n",
      "### What the Entire Code Does\n",
      "Overall, the line of code:\n",
      "```python\n",
      "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "```\n",
      "defines a generator that will yield each unique author from the list of `books`. It filters out any books that do not have a defined author, and ensures that each unique author is yielded only once due to the nature of sets in Python.\n",
      "\n",
      "### Example Use Case\n",
      "If you had a list of `books` like this:\n",
      "```python\n",
      "books = [\n",
      "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
      "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
      "    {\"title\": \"Book 3\", \"author\": None},\n",
      "    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n",
      "]\n",
      "```\n",
      "The code would yield:\n",
      "- \"Author A\"\n",
      "- \"Author B\"\n",
      "\n",
      "You would get \"Author A\" once, since it appears multiple times, and \"Author B\", but it would skip the book without an author.\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "\n",
    "def get_openai_response(question):\n",
    "    \"\"\"Fetches a response from OpenAI's API using the latest SDK.\"\"\"\n",
    "    openai.api_key = api_key  # Replace with your actual OpenAI API key\n",
    "    \n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_GPT,  # Change to \"gpt-3.5-turbo\" if preferred\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a knowledgeable AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching OpenAI response: {str(e)}\"\n",
    "\n",
    "\n",
    "openai_answer = get_openai_response(question)\n",
    "print(f\"\\nOpenAI's Answer:\\n{openai_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ollama's Answer:\n",
      "Error fetching Ollama response: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def get_ollama_response(question):\n",
    "    \"\"\"Fetches a response from an Ollama model running locally.\"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"mistral\",  # Change to your preferred local model\n",
    "            messages=[{\"role\": \"user\", \"content\": question}]\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching Ollama response: {str(e)}\"\n",
    "\n",
    "ollama_answer = get_ollama_response(question)\n",
    "print(f\"\\nOllama's Answer:\\n{ollama_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1d62a-618c-4181-be7d-884dfabc28e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
